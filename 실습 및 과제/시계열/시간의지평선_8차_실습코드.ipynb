{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'TRAIN_WINDOW_SIZE':90, # 90일치로 학습\n",
    "    'PREDICT_SIZE':21, # 21일치 예측\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    'BATCH_SIZE':1024,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.cuda.manual_seed_all(seed) # multi-gpu seed 고정\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>개당판매금액</th>\n",
       "      <th>언급량</th>\n",
       "      <th>판매량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0007</td>\n",
       "      <td>B002-C003-0038</td>\n",
       "      <td>B002-00001</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>0.84131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0007</td>\n",
       "      <td>B002-C003-0038</td>\n",
       "      <td>B002-00001</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>0.91383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0007</td>\n",
       "      <td>B002-C003-0038</td>\n",
       "      <td>B002-00001</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>1.45053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0007</td>\n",
       "      <td>B002-C003-0038</td>\n",
       "      <td>B002-00001</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>2.42239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0007</td>\n",
       "      <td>B002-C003-0038</td>\n",
       "      <td>B002-00001</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>1.87119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293505</th>\n",
       "      <td>15889</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0004</td>\n",
       "      <td>B002-C003-0020</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>49800.0</td>\n",
       "      <td>5.51203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293506</th>\n",
       "      <td>15889</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0004</td>\n",
       "      <td>B002-C003-0020</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>49800.0</td>\n",
       "      <td>3.52480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293507</th>\n",
       "      <td>15889</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0004</td>\n",
       "      <td>B002-C003-0020</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>49800.0</td>\n",
       "      <td>4.03249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293508</th>\n",
       "      <td>15889</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0004</td>\n",
       "      <td>B002-C003-0020</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>49800.0</td>\n",
       "      <td>5.88917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293509</th>\n",
       "      <td>15889</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0004</td>\n",
       "      <td>B002-C003-0020</td>\n",
       "      <td>B002-03799</td>\n",
       "      <td>49800.0</td>\n",
       "      <td>5.07687</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7293510 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID             대분류             중분류             소분류         브랜드  \\\n",
       "0            0  B002-C001-0002  B002-C002-0007  B002-C003-0038  B002-00001   \n",
       "1            0  B002-C001-0002  B002-C002-0007  B002-C003-0038  B002-00001   \n",
       "2            0  B002-C001-0002  B002-C002-0007  B002-C003-0038  B002-00001   \n",
       "3            0  B002-C001-0002  B002-C002-0007  B002-C003-0038  B002-00001   \n",
       "4            0  B002-C001-0002  B002-C002-0007  B002-C003-0038  B002-00001   \n",
       "...        ...             ...             ...             ...         ...   \n",
       "7293505  15889  B002-C001-0002  B002-C002-0004  B002-C003-0020  B002-03799   \n",
       "7293506  15889  B002-C001-0002  B002-C002-0004  B002-C003-0020  B002-03799   \n",
       "7293507  15889  B002-C001-0002  B002-C002-0004  B002-C003-0020  B002-03799   \n",
       "7293508  15889  B002-C001-0002  B002-C002-0004  B002-C003-0020  B002-03799   \n",
       "7293509  15889  B002-C001-0002  B002-C002-0004  B002-C003-0020  B002-03799   \n",
       "\n",
       "          개당판매금액      언급량  판매량  \n",
       "0        13500.0  0.84131    0  \n",
       "1        13500.0  0.91383    0  \n",
       "2        13500.0  1.45053    0  \n",
       "3        13500.0  2.42239    0  \n",
       "4        13500.0  1.87119    0  \n",
       "...          ...      ...  ...  \n",
       "7293505  49800.0  5.51203    0  \n",
       "7293506  49800.0  3.52480    0  \n",
       "7293507  49800.0  4.03249    0  \n",
       "7293508  49800.0  5.88917    0  \n",
       "7293509  49800.0  5.07687    0  \n",
       "\n",
       "[7293510 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1 = pd.read_csv('./data/preprocess_train_data.csv').drop(columns=['제품']).fillna(0)\n",
    "train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = train1.groupby('ID')\n",
    "\n",
    "scale_min_dict = {}\n",
    "scale_max_dict = {}\n",
    "\n",
    "for name, group in groups:\n",
    "    scale_min_dict[name] = group['판매량'].min()\n",
    "    scale_max_dict[name] = group['판매량'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "def scale_series(s):\n",
    "    return pd.Series(scaler.fit_transform(s.values.reshape(-1, 1)).flatten(), index=s.index)\n",
    "\n",
    "train1['판매량'] = train1.groupby('ID')['판매량'].transform(scale_series)\n",
    "train1['개당판매금액'] = scaler.fit_transform(train1['개당판매금액'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['대분류', '중분류', '소분류', '브랜드']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoder.fit(train1[col])\n",
    "    train1[col] = label_encoder.transform(train1[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "def weightedsampler(train_data):\n",
    "    train_category = train_data[:,0,1].astype(int)\n",
    "\n",
    "    cat_count = np.array([len(np.where(train_category==t)[0]) for t in np.unique(train_category)])\n",
    "    weight = 1. / cat_count\n",
    "    samples_weight = np.array([weight[t] for t in train_category])\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))\n",
    "\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.Y is not None:\n",
    "            return torch.Tensor(self.X[index]), torch.Tensor(self.Y[index])\n",
    "        return torch.Tensor(self.X[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moving_avg(torch.nn.Module):\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = torch.nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "class series_decomp(torch.nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        residual = x - moving_mean\n",
    "        return moving_mean, residual \n",
    "        \n",
    "class LTSF_DLinear(torch.nn.Module):\n",
    "    def __init__(self, window_size, forcast_size, kernel_size, individual, feature_size):\n",
    "        super(LTSF_DLinear, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.forcast_size = forcast_size\n",
    "        self.decompsition = series_decomp(kernel_size)\n",
    "        self.individual = individual\n",
    "        self.channels = feature_size\n",
    "        if self.individual:\n",
    "            self.Linear_Seasonal = torch.nn.ModuleList()\n",
    "            self.Linear_Trend = torch.nn.ModuleList()\n",
    "            for i in range(self.channels):\n",
    "                self.Linear_Trend.append(torch.nn.Linear(self.window_size, self.forcast_size))\n",
    "                # self.Linear_Trend[i].weight = torch.nn.Parameter((1/self.window_size)*torch.ones([self.forcast_size, self.window_size]))\n",
    "                self.Linear_Seasonal.append(torch.nn.Linear(self.window_size, self.forcast_size))\n",
    "                # self.Linear_Seasonal[i].weight = torch.nn.Parameter((1/self.window_size)*torch.ones([self.forcast_size, self.window_size]))\n",
    "        else:\n",
    "            self.Linear_Trend = torch.nn.Linear(self.window_size, self.forcast_size)\n",
    "            # self.Linear_Trend.weight = torch.nn.Parameter((1/self.window_size)*torch.ones([self.forcast_size, self.window_size]))\n",
    "            self.Linear_Seasonal = torch.nn.Linear(self.window_size,  self.forcast_size)\n",
    "            # self.Linear_Seasonal.weight = torch.nn.Parameter((1/self.window_size)*torch.ones([self.forcast_size, self.window_size]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[:, :, 1:] # 모델 학습 시 ID 제외\n",
    "        trend_init, seasonal_init = self.decompsition(x)\n",
    "        trend_init, seasonal_init = trend_init.permute(0,2,1), seasonal_init.permute(0,2,1)\n",
    "        if self.individual:\n",
    "            trend_output = torch.zeros([trend_init.size(0), trend_init.size(1), self.forcast_size], dtype=trend_init.dtype).to(trend_init.device)\n",
    "            seasonal_output = torch.zeros([seasonal_init.size(0), seasonal_init.size(1), self.forcast_size], dtype=seasonal_init.dtype).to(seasonal_init.device)\n",
    "            for idx in range(self.channels):\n",
    "                trend_output[:, idx, :] = self.Linear_Trend[idx](trend_init[:, idx, :])\n",
    "                seasonal_output[:, idx, :] = self.Linear_Seasonal[idx](seasonal_init[:, idx, :])                \n",
    "        else:\n",
    "            trend_output = self.Linear_Trend(trend_init)\n",
    "            seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "        x = seasonal_output + trend_output\n",
    "        x = x.permute(0,2,1) # [batch_size, forcast_size, channels]\n",
    "        x = x[:, :, -1].squeeze(1) # 마지막 column(판매량)만 고려\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricMSELoss(nn.Module):\n",
    "    def __init__(self, alpha = 0.1):\n",
    "        super(AsymmetricMSELoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        diff = predictions - targets\n",
    "        squared_diff = diff ** 2\n",
    "        loss = torch.where(diff >= 0, self.alpha * squared_diff, (1 - self.alpha) * squared_diff)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class ASAM:\n",
    "    def __init__(self, optimizer, model, rho=0.5, eta=0.01):\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.rho = rho\n",
    "        self.eta = eta\n",
    "        self.state = defaultdict(dict)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def ascent_step(self):\n",
    "        wgrads = []\n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            t_w = self.state[p].get(\"eps\")\n",
    "            if t_w is None:\n",
    "                t_w = torch.clone(p).detach()\n",
    "                self.state[p][\"eps\"] = t_w\n",
    "            if 'weight' in n:\n",
    "                t_w[...] = p[...]\n",
    "                t_w.abs_().add_(self.eta)\n",
    "                p.grad.mul_(t_w)\n",
    "            wgrads.append(torch.norm(p.grad, p=2))\n",
    "        wgrad_norm = torch.norm(torch.stack(wgrads), p=2) + 1.e-16\n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            t_w = self.state[p].get(\"eps\")\n",
    "            if 'weight' in n:\n",
    "                p.grad.mul_(t_w)\n",
    "            eps = t_w\n",
    "            eps[...] = p.grad[...]\n",
    "            eps.mul_(self.rho / wgrad_norm)\n",
    "            p.add_(eps)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def descent_step(self):\n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            p.sub_(self.state[p][\"eps\"])\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def compute_for_cat(cat_df, ids):\n",
    "    sub_cat_df = cat_df[cat_df[:, 0] == ids]\n",
    "    true_Y, pred_Y = sub_cat_df[:, 2], sub_cat_df[:, 3]\n",
    "\n",
    "    days_denom = np.sum(true_Y) + 1e-10\n",
    "    days_num = np.abs(true_Y - pred_Y)\n",
    "    days_denom_with_eps = np.maximum(true_Y, pred_Y) + 1e-10\n",
    "    days = (days_num / days_denom_with_eps) * (true_Y / days_denom)\n",
    "    return np.sum(days)\n",
    "\n",
    "def compute_PSFA(sub_df):\n",
    "    psfa_m = np.zeros(5)\n",
    "\n",
    "    for cat in range(5):\n",
    "        cat_df = sub_df[sub_df[:, :, 1] == cat]\n",
    "        cat_ids, _ = np.unique(cat_df[:, 0], return_counts=True)\n",
    "        cat_id_list = np.zeros(len(cat_ids))\n",
    "\n",
    "        results = Parallel(n_jobs=-1)(delayed(compute_for_cat)(cat_df, ids) for _, ids in enumerate(cat_ids))\n",
    "\n",
    "        cat_id_list = np.array(results)\n",
    "        psfa_m[cat] = 1 - (np.sum(cat_id_list) / len(cat_id_list))\n",
    "    return np.mean(psfa_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, minimizer, train_loader, val_loader, device, scheduler):\n",
    "   # model = nn.DataParallel(model, device_ids=[0, 1], output_device=0)\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = AsymmetricMSELoss().to(device)\n",
    "    # criterion = nn.HuberLoss(delta=0.1).to(device)\n",
    "\n",
    "    best_score = 0\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for X, Y in tqdm(iter(train_loader)):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            \n",
    "            # Ascent Step\n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            loss.backward()\n",
    "            minimizer.ascent_step()\n",
    "\n",
    "            # Descent Step\n",
    "            loss_2 = criterion(model(X), Y)\n",
    "            loss_2.backward()\n",
    "            minimizer.descent_step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        val_loss, psfa = validation(model, val_loader, criterion, device)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        model_save = ''\n",
    "        if psfa > best_score:\n",
    "            best_score = psfa\n",
    "            best_model = model\n",
    "            model_save = 'Model Saved'\n",
    "        \n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}] PSFA : [{psfa:.5f}] {model_save}')\n",
    "    return best_model, best_score\n",
    "\n",
    "def validation(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    sub_df_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, Y in tqdm(iter(val_loader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            X_ids = X[:, :21, :2].detach().cpu().numpy()\n",
    "            Y = Y.detach().cpu().numpy().reshape(Y.shape[0], Y.shape[1], 1)\n",
    "            pred_Y = output.detach().cpu().numpy().reshape(output.shape[0], output.shape[1], 1)\n",
    "            \n",
    "            sub_df = np.concatenate([X_ids, Y, pred_Y], axis=2)\n",
    "\n",
    "            sub_df_list.append(sub_df)\n",
    "        \n",
    "        sub_df = np.concatenate(sub_df_list, axis=0)\n",
    "        PSFA = compute_PSFA(sub_df)\n",
    "    \n",
    "    return np.mean(val_loss) , PSFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X in tqdm(iter(test_loader)):\n",
    "            X = X.to(device)\n",
    "            output = model(X)\n",
    "            output = output.cpu().numpy()\n",
    "            predictions.extend(output)\n",
    "    \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_input = np.load('./data/new_data/train1_input_mean_stds.npy')\n",
    "train1_target = np.load('./data/new_data/train1_target_mean_stds.npy')\n",
    "test_input = np.load('./data/new_data/test_input_mean_stds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids = train1_input[:, 0, 0].astype(int)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_input, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 ==================================================\n",
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:24<00:00, 198.01it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 314.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.00877] Val Loss : [0.00825] PSFA : [0.55341] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 213.40it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 313.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.00822] Val Loss : [0.00826] PSFA : [0.55315] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.77it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 317.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.00823] Val Loss : [0.00826] PSFA : [0.55360] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.72it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 316.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.00819] Val Loss : [0.00826] PSFA : [0.55291] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 212.09it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 310.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train Loss : [0.00820] Val Loss : [0.00825] PSFA : [0.55383] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 211.36it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 319.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6] Train Loss : [0.00821] Val Loss : [0.00825] PSFA : [0.55400] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 213.56it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 305.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7] Train Loss : [0.00821] Val Loss : [0.00826] PSFA : [0.55306] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 209.55it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 310.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8] Train Loss : [0.00822] Val Loss : [0.00826] PSFA : [0.55358] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 212.89it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 313.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9] Train Loss : [0.00822] Val Loss : [0.00826] PSFA : [0.55266] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.53it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 302.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10] Train Loss : [0.00822] Val Loss : [0.00826] PSFA : [0.55352] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 87.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "fold: 1 ==================================================\n",
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 211.93it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 304.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.00902] Val Loss : [0.00831] PSFA : [0.55475] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 214.45it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 303.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.00821] Val Loss : [0.00831] PSFA : [0.55549] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 211.31it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 304.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.00820] Val Loss : [0.00831] PSFA : [0.55565] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.82it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 307.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.00818] Val Loss : [0.00831] PSFA : [0.55509] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 209.41it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 309.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train Loss : [0.00822] Val Loss : [0.00831] PSFA : [0.55520] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 211.53it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 300.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6] Train Loss : [0.00820] Val Loss : [0.00831] PSFA : [0.55511] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 209.20it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 299.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7] Train Loss : [0.00820] Val Loss : [0.00831] PSFA : [0.55532] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.17it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 305.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8] Train Loss : [0.00820] Val Loss : [0.00832] PSFA : [0.55635] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 213.09it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 305.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9] Train Loss : [0.00821] Val Loss : [0.00831] PSFA : [0.55537] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.13it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 286.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10] Train Loss : [0.00820] Val Loss : [0.00832] PSFA : [0.55537] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 89.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "fold: 2 ==================================================\n",
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 211.53it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 306.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.00884] Val Loss : [0.00825] PSFA : [0.55060] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.54it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 304.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.00819] Val Loss : [0.00825] PSFA : [0.55031] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 213.77it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 283.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.00819] Val Loss : [0.00826] PSFA : [0.55079] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.34it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 280.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.00820] Val Loss : [0.00826] PSFA : [0.55068] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 206.52it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 306.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train Loss : [0.00820] Val Loss : [0.00825] PSFA : [0.54995] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 208.10it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 282.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6] Train Loss : [0.00819] Val Loss : [0.00826] PSFA : [0.55072] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 212.76it/s]\n",
      "100%|██████████| 541/541 [00:02<00:00, 260.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7] Train Loss : [0.00819] Val Loss : [0.00826] PSFA : [0.55051] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 213.87it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 275.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8] Train Loss : [0.00819] Val Loss : [0.00826] PSFA : [0.55146] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 208.38it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 278.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9] Train Loss : [0.00819] Val Loss : [0.00825] PSFA : [0.54982] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 211.24it/s]\n",
      "100%|██████████| 541/541 [00:02<00:00, 245.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10] Train Loss : [0.00820] Val Loss : [0.00826] PSFA : [0.55087] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 88.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "fold: 3 ==================================================\n",
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 212.46it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 279.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.00879] Val Loss : [0.00831] PSFA : [0.55390] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 209.25it/s]\n",
      "100%|██████████| 541/541 [00:02<00:00, 260.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.00818] Val Loss : [0.00830] PSFA : [0.55381] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.19it/s]\n",
      "100%|██████████| 541/541 [00:02<00:00, 257.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.00818] Val Loss : [0.00831] PSFA : [0.55337] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 209.70it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 276.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.00817] Val Loss : [0.00831] PSFA : [0.55300] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 211.56it/s]\n",
      "100%|██████████| 541/541 [00:02<00:00, 263.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train Loss : [0.00817] Val Loss : [0.00831] PSFA : [0.55328] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.61it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 302.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6] Train Loss : [0.00818] Val Loss : [0.00831] PSFA : [0.55374] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.26it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 304.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7] Train Loss : [0.00819] Val Loss : [0.00831] PSFA : [0.55294] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 205.81it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 307.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8] Train Loss : [0.00818] Val Loss : [0.00831] PSFA : [0.55379] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 208.72it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 301.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9] Train Loss : [0.00819] Val Loss : [0.00831] PSFA : [0.55257] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 212.07it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 304.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10] Train Loss : [0.00817] Val Loss : [0.00831] PSFA : [0.55317] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 87.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "fold: 4 ==================================================\n",
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 208.20it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 305.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.00891] Val Loss : [0.00829] PSFA : [0.55344] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.50it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 310.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.00821] Val Loss : [0.00830] PSFA : [0.55337] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 212.22it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 301.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.00820] Val Loss : [0.00830] PSFA : [0.55286] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 211.05it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 303.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.00819] Val Loss : [0.00830] PSFA : [0.55275] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 213.95it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 279.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train Loss : [0.00821] Val Loss : [0.00830] PSFA : [0.55297] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 207.16it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 280.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6] Train Loss : [0.00820] Val Loss : [0.00829] PSFA : [0.55279] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.61it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 285.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7] Train Loss : [0.00821] Val Loss : [0.00830] PSFA : [0.55180] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 207.27it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 305.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8] Train Loss : [0.00819] Val Loss : [0.00829] PSFA : [0.55284] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 211.63it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 280.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9] Train Loss : [0.00820] Val Loss : [0.00830] PSFA : [0.55235] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.52it/s]\n",
      "100%|██████████| 541/541 [00:02<00:00, 265.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10] Train Loss : [0.00821] Val Loss : [0.00830] PSFA : [0.55344] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 88.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "fold: 5 ==================================================\n",
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 212.30it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 279.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.00898] Val Loss : [0.00826] PSFA : [0.55245] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 208.41it/s]\n",
      "100%|██████████| 541/541 [00:02<00:00, 246.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.00819] Val Loss : [0.00827] PSFA : [0.55380] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.20it/s]\n",
      "100%|██████████| 541/541 [00:02<00:00, 268.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.00821] Val Loss : [0.00826] PSFA : [0.55268] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.74it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 275.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.00820] Val Loss : [0.00828] PSFA : [0.55169] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 209.81it/s]\n",
      "100%|██████████| 541/541 [00:02<00:00, 243.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train Loss : [0.00820] Val Loss : [0.00827] PSFA : [0.55310] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 208.25it/s]\n",
      "100%|██████████| 541/541 [00:02<00:00, 261.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6] Train Loss : [0.00820] Val Loss : [0.00827] PSFA : [0.55315] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 211.88it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 276.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7] Train Loss : [0.00820] Val Loss : [0.00828] PSFA : [0.55356] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 209.75it/s]\n",
      "100%|██████████| 541/541 [00:02<00:00, 257.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8] Train Loss : [0.00821] Val Loss : [0.00827] PSFA : [0.55305] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 209.50it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 309.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9] Train Loss : [0.00820] Val Loss : [0.00827] PSFA : [0.55356] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 214.07it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 308.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10] Train Loss : [0.00820] Val Loss : [0.00827] PSFA : [0.55307] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 88.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "fold: 6 ==================================================\n",
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 212.51it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 309.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.00875] Val Loss : [0.00827] PSFA : [0.55578] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 211.51it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 307.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.00822] Val Loss : [0.00827] PSFA : [0.55536] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 213.39it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 303.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.00821] Val Loss : [0.00827] PSFA : [0.55586] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 209.66it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 307.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.00822] Val Loss : [0.00827] PSFA : [0.55594] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 209.80it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 299.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train Loss : [0.00823] Val Loss : [0.00827] PSFA : [0.55595] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 209.76it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 304.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6] Train Loss : [0.00821] Val Loss : [0.00827] PSFA : [0.55517] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 208.95it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 311.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7] Train Loss : [0.00821] Val Loss : [0.00827] PSFA : [0.55571] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 211.72it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 305.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8] Train Loss : [0.00822] Val Loss : [0.00827] PSFA : [0.55591] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 214.67it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 305.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9] Train Loss : [0.00821] Val Loss : [0.00827] PSFA : [0.55619] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 211.37it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 283.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10] Train Loss : [0.00820] Val Loss : [0.00827] PSFA : [0.55581] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 88.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "fold: 7 ==================================================\n",
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 207.13it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 306.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.00874] Val Loss : [0.00836] PSFA : [0.54798] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.62it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 283.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.00818] Val Loss : [0.00837] PSFA : [0.54800] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:22<00:00, 211.53it/s]\n",
      "100%|██████████| 541/541 [00:02<00:00, 263.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.00819] Val Loss : [0.00836] PSFA : [0.54806] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 211.14it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 271.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.00817] Val Loss : [0.00836] PSFA : [0.54823] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 210.27it/s]\n",
      "100%|██████████| 541/541 [00:01<00:00, 289.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train Loss : [0.00818] Val Loss : [0.00836] PSFA : [0.54831] Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4861/4861 [00:23<00:00, 207.67it/s]\n",
      "100%|██████████| 541/541 [00:02<00:00, 260.58it/s]\n",
      "/tmp/ipykernel_2234/1170797840.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "Process LokyProcess-61:\n",
      "/tmp/ipykernel_2234/1170797840.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/saturncloud/envs/saturn/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/saturncloud/envs/saturn/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 473, in _process_worker\n",
      "    del call_item\n",
      "KeyboardInterrupt\n",
      "/tmp/ipykernel_2234/1170797840.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "/tmp/ipykernel_2234/1170797840.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "/tmp/ipykernel_2234/1170797840.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "/tmp/ipykernel_2234/1170797840.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "/tmp/ipykernel_2234/1170797840.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "/tmp/ipykernel_2234/1170797840.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "/tmp/ipykernel_2234/1170797840.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "/tmp/ipykernel_2234/1170797840.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart Training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m infer_model, fold_score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m pred \u001b[38;5;241m=\u001b[39m inference(infer_model, test_loader, device)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 추론 결과를 inverse scaling\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, minimizer, train_loader, val_loader, device, scheduler)\u001b[0m\n\u001b[1;32m     27\u001b[0m     minimizer\u001b[38;5;241m.\u001b[39mdescent_step()\n\u001b[1;32m     29\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m---> 31\u001b[0m val_loss, psfa \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[15], line 69\u001b[0m, in \u001b[0;36mvalidation\u001b[0;34m(model, val_loader, criterion, device)\u001b[0m\n\u001b[1;32m     66\u001b[0m         sub_df_list\u001b[38;5;241m.\u001b[39mappend(sub_df)\n\u001b[1;32m     68\u001b[0m     sub_df \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(sub_df_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m     PSFA \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_PSFA\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(val_loss) , PSFA\n",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m, in \u001b[0;36mcompute_PSFA\u001b[0;34m(sub_df)\u001b[0m\n\u001b[1;32m     18\u001b[0m cat_ids, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(cat_df[:, \u001b[38;5;241m0\u001b[39m], return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m cat_id_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(cat_ids))\n\u001b[0;32m---> 21\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_for_cat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcat_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m cat_id_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(results)\n\u001b[1;32m     24\u001b[0m psfa_m[cat] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (np\u001b[38;5;241m.\u001b[39msum(cat_id_list) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(cat_id_list))\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/joblib/parallel.py:1944\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/joblib/parallel.py:1587\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1587\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1698\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1699\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold_num, (train_idx, valid_idx) in enumerate(skf.split(train1_input, train_input_ids)):\n",
    "    print(f'fold: {fold_num}', '='*50)\n",
    "    \n",
    "    train_input, train_target = train1_input[train_idx], train1_target[train_idx]\n",
    "    val_input, val_target = train1_input[valid_idx], train1_target[valid_idx]\n",
    "\n",
    "    train_dataset = CustomDataset(train_input, train_target)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=16, pin_memory=True, sampler=weightedsampler(train_input))\n",
    "\n",
    "    val_dataset = CustomDataset(val_input, val_target)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "    model = LTSF_DLinear(window_size=CFG['TRAIN_WINDOW_SIZE'], forcast_size=CFG[\"PREDICT_SIZE\"], kernel_size=25,individual=False, feature_size=1)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "    minimizer = ASAM(optimizer, model)\n",
    "\n",
    "    scheduler = None\n",
    "\n",
    "    print(\"Start Training\")\n",
    "    infer_model, fold_score = train(model, minimizer, train_loader, val_loader, device, scheduler)\n",
    "\n",
    "    pred = inference(infer_model, test_loader, device)\n",
    "\n",
    "    # 추론 결과를 inverse scaling\n",
    "    for idx in range(len(pred)):\n",
    "        pred[idx, :] = pred[idx, :] * (scale_max_dict[idx] - scale_min_dict[idx]) + scale_min_dict[idx]\n",
    "\n",
    "    torch.save(infer_model.state_dict(), f'./data/ensemble_submit/linear_idsplit_{fold_num}_{fold_score}.pth')\n",
    "\n",
    "    pred = np.round(pred, 0).astype(int)\n",
    "    \n",
    "    submit = pd.read_csv('./data/sample_submission.csv')\n",
    "    submit.iloc[:,1:] = pred\n",
    "    submit.to_csv(f'./submit/linear_idsplit_{fold_num}_{fold_score}.csv', index=False)\n",
    "    \n",
    "    print(\"Done\")\n",
    "\n",
    "    del train_input, train_target, val_input, val_target, train_dataset, train_loader, val_dataset, val_loader, model, optimizer, scheduler, infer_model, pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
